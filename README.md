
---

```markdown
# ğŸ¬ Django + React Real-Time Scraper Engine

A **full-stack real-time movie scraper and aggregator**, designed as a personal dashboard that can query multiple sites **simultaneously** â€” even **Cloudflare-protected** ones â€” and stream the results back to a web interface **in real-time**.

---

## ğŸ§  Core Architecture

- **Backend:** Django + Django Channels (WebSockets)  
- **Frontend:** React (built with **Vite**, served directly by Django)  
- **Task Queuing:** Celery + Redis  
- **Scraping Engine:**
  - `requests` + `BeautifulSoup` â†’ for fast and simple sites  
  - `Selenium` + **Brave Browser** â†’ for Cloudflare-protected or JavaScript-heavy sites  
- **Concurrency Model:**  
  - `fast_queue` â†’ for lightweight request-based scrapers  
  - `profile_queue` â†’ for heavy Selenium tasks (run one at a time to prevent Brave profile corruption)

---

## ğŸ“ Project Structure

```

my_search_project/
â”œâ”€â”€ backend/
â”‚   â”œâ”€â”€ manage.py
â”‚   â”œâ”€â”€ train_profile.py        <-- IMPORTANT: warms up Brave profile
â”‚   â”œâ”€â”€ requirements.txt
â”‚   â”œâ”€â”€ scraper_project/        (Django project)
â”‚   â””â”€â”€ scraper_api/            (Django app)
â”œâ”€â”€ frontend/
â”‚   â”œâ”€â”€ dist/                   <-- React app build output
â”‚   â”œâ”€â”€ src/
â”‚   â”œâ”€â”€ package.json
â”‚   â””â”€â”€ vite.config.js          <-- Configured for Django
â””â”€â”€ README.md                   <-- This file

````

---

## âš™ï¸ Prerequisites

1. **Python 3.10+** (âœ… You are using 3.14 â€” perfect)  
2. **Node.js & npm** â€” for building the React app  
3. **Docker Desktop** â€” to run Redis easily  
4. **Brave Browser** â€” must be installed in the default location  

---

## ğŸš€ Step 1: One-Time Project Setup

### ğŸŸ¥ A. Start Redis (Docker)

Start Redis in a Docker container (only once):

```bash
docker run -d -p 6379:6379 --name my-scraper-redis redis
````

> ğŸ’¡ If you get â€œport already allocatedâ€, it just means Redis is already running (visible in Docker Desktop).

---

### ğŸŸ© B. Backend Setup

Open a terminal in the `backend/` folder.

#### 1. Create and activate a virtual environment

```bash
python -m venv venv
.\venv\Scripts\activate
```

#### 2. Install dependencies

```bash
pip install -r requirements.txt
pip install selenium-stealth webdriver-manager
```

#### 3. Initialize the database

```bash
python manage.py migrate
```

#### 4. Create an admin user

```bash
python manage.py createsuperuser
```

---

### ğŸŸ¦ C. Frontend Setup

Open a **new terminal** in the `frontend/` folder.

#### 1. Install Node modules

```bash
npm install
```

#### 2. Build the React app

```bash
npm run build
```

> ğŸ—ï¸ This creates the `frontend/dist/` folder, which Django will serve.

---

### ğŸ”¥ D. Browser Profile Warm-Up (**CRITICAL**)

This step â€œtrainsâ€ your Selenium Brave profile to look like a real human user and defeat Cloudflare.

#### 1. Close **all** Brave browser windows.

#### 2. Run the training script:

```bash
# In backend/ (with venv active)
python train_profile.py
```

A **Brave window** will pop up â€” this is your **BraveSeleniumProfile**.

#### 3. In that Brave window:

1. Go to [https://google.com](https://google.com) â†’ log in with your Google account (this builds trust).
2. Visit and manually solve CAPTCHAs on:

   * [https://hdhub4u.pictures/](https://hdhub4u.pictures/)
   * [https://vegamovies.gripe/](https://vegamovies.gripe/)
   * [https://vegamovies.talk/](https://vegamovies.talk/)
3. Once all sites load normally â†’ **close Brave** and stop the script (`CTRL + C`).

âœ… Your profile is now warmed and trusted.

---

## ğŸƒ Step 2: Run the Project

You need **three backend terminals** (plus Docker running Redis).
You do **not** need to run `npm start`.

---

### ğŸ§© Terminal 1: Fast Queue Worker

Handles lightweight `requests`-based scrapers.

```bash
# In backend/
.\venv\Scripts\activate
celery -A scraper_project worker --pool=threads -Q fast_queue -c 12 --loglevel=info
```

---

### ğŸ§© Terminal 2: Selenium/Profile Queue Worker

Handles Selenium scrapers one at a time (safe mode).

```bash
# In backend/
.\venv\Scripts\activate
celery -A scraper_project worker --pool=threads -Q profile_queue -c 1 --loglevel=info
```

---

### ğŸ§© Terminal 3: Web Server (Daphne)

Serves React frontend + WebSocket connections.

```bash
# In backend/
.\venv\Scripts\activate
daphne -p 8000 scraper_project.asgi:application
```

Your app is live ğŸ‰

* **Frontend:** [http://localhost:8000](http://localhost:8000)
* **Admin Panel:** [http://localhost:8000/admin](http://localhost:8000/admin)

---

## âš™ï¸ Step 3: Configure Scrapers (via Admin)

1. Go to [http://localhost:8000/admin](http://localhost:8000/admin)
2. Log in with your superuser credentials.
3. Under **â€œSite Sourcesâ€**, click **â€œAdd Site Source +â€**.
4. Fill in each siteâ€™s scraping pattern.

---

### ğŸ§© Example: HDHub4u

| Field                         | Value                                                |
| ----------------------------- | ---------------------------------------------------- |
| **Name**                      | HDHub4u                                              |
| **Base URL**                  | [https://hdhub4u.pictures](https://hdhub4u.pictures) |
| **Search Type**               | GET Parameter                                        |
| **Search Endpoint**           | `/?s=%QUERY%`                                        |
| **Requires playwright**       | âœ… *(Sends to Selenium queue)*                        |
| **Result container selector** | `li.thumb`                                           |
| **Result title selector**     | `figcaption a p`                                     |
| **Result link selector**      | `figcaption a`                                       |
| **Result poster selector**    | `figure img`                                         |
| **Result poster attribute**   | `src`                                                |

---

### ğŸ§© Example: Vegamovies.talk

| Field                         | Value                                              |
| ----------------------------- | -------------------------------------------------- |
| **Name**                      | Vegamovies.talk                                    |
| **Base URL**                  | [https://vegamovies.talk](https://vegamovies.talk) |
| **Search Type**               | POST API                                           |
| **Search Endpoint**           | `/`                                                |
| **Post Payload Template**     | `do=search`, `subaction=search`, `story=%QUERY%`   |
| **Requires playwright**       | âœ…                                                  |
| **Result container selector** | `article.post-item`                                |
| **Result title selector**     | `h3.entry-title a`                                 |
| **Result link selector**      | `h3.entry-title a`                                 |
| **Result poster selector**    | `img.blog-picture`                                 |
| **Result poster attribute**   | `src`                                              |

---

### ğŸ§© Example: Vegamovies.gripe

| Field                         | Value                                                |
| ----------------------------- | ---------------------------------------------------- |
| **Name**                      | Vegamovies                                           |
| **Base URL**                  | [https://vegamovies.gripe](https://vegamovies.gripe) |
| **Search Type**               | GET Parameter                                        |
| **Search Endpoint**           | `/?s=%QUERY%`                                        |
| **Requires playwright**       | âœ…                                                    |
| **Result container selector** | `article.grid-item`                                  |
| **Result title selector**     | `h2.post-title a`                                    |
| **Result link selector**      | `h2.post-title a`                                    |
| **Result poster selector**    | `img.wp-post-image`                                  |
| **Result poster attribute**   | `src`                                                |

---

## ğŸ”Œ WebSocket API

**Endpoint:**

```
ws://localhost:8000/ws/search/
```

### ğŸ”„ Client â†’ Server (Start a Search)

```json
{
  "action": "search",
  "term": "your movie"
}
```

### ğŸ“¡ Server â†’ Client (Result)

```json
{
  "source": "SiteName",
  "title": "Movie Title",
  "link": "https://...",
  "poster": "https://..."
}
```

### âš ï¸ Server â†’ Client (Error)

```json
{
  "error": true,
  "message": "Failed to fetch data from ..."
}
```

---

## ğŸ§­ Notes & Tips

* Always **train your Brave profile** before using Selenium scrapers.
* You can add or remove sources dynamically via the Admin Panel.
* The **frontend is static** â€” you only rebuild (`npm run build`) if you modify it.
* For production, configure your `.env` and run **Daphne + Celery workers** with a process manager like `supervisor` or `systemd`.

---

## ğŸ Thatâ€™s It!

Your **Django + React Real-Time Scraper Engine** is ready.
You now have a **parallel, Cloudflare-resistant scraping system** that streams movie results instantly.
